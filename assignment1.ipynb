{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Lock, Process, Queue, current_process, Pool\n",
    "import random\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "import time\n",
    "import sys\n",
    "#import queue # imported for using queue.Empty exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks: Purchase Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate list of possible choices to pick from for users\n",
    "allUsers = set([])\n",
    "allItems = set([])\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    allUsers.add(user)\n",
    "    allItems.add(item)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# optionally save it to disk (Also practicing parallelism \n",
    "# here, it will be useful later on)\n",
    "persist = False\n",
    "processes = []\n",
    "\n",
    "if persist:\n",
    "    def save_items():\n",
    "        itemsSet = open(\"items_set.txt\", 'w')\n",
    "        for l in allItems:\n",
    "            itemsSet.write(l + '\\n')\n",
    "        itemsSet.close()\n",
    "        \n",
    "    def save_users():\n",
    "        usersSet = open(\"users_set.txt\", 'w')\n",
    "        for l in allUsers:\n",
    "            usersSet.write(l + '\\n')\n",
    "        usersSet.close()\n",
    "        \n",
    "    def parallel_execute():\n",
    "        p = Process(target=save_items)\n",
    "        q = Process(target=save_users)\n",
    "        processes.append(p)\n",
    "        processes.append(q)\n",
    "        p.start()\n",
    "        q.start()\n",
    "        p.join() # comment this out to allow other cells to run\n",
    "        q.join() # ''\n",
    "        #p.close()\n",
    "        #q.close()\n",
    "    parallel_execute()\n",
    "    \n",
    "uniqueUsers = list(allUsers)\n",
    "uniqueItems = list(allItems)\n",
    "print('Done') # should let me run other cells while jobs finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sets of data in memory\n",
    "train_200k = []\n",
    "purchases_200k = []\n",
    "#pbar = tqdm_notebook(total=200000, desc='Progress:')\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    train_200k.append(l)\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    # appending as tuple to allow hash collision detection\n",
    "    # later on down the line\n",
    "    purchases_200k.append((user,item))\n",
    "    #pbar.update(1)\n",
    "#pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load presaved data\n",
    "random.shuffle(train_200k)\n",
    "random.shuffle(purchases_200k)\n",
    "train_100k = train_200k[:100000]\n",
    "validation_positives = purchases_200k[100000:]\n",
    "\n",
    "v_negs = []\n",
    "for l in open(\"validation_negatives.txt\"):\n",
    "    obj = l.split('\\'')[1::2]\n",
    "    v_negs.append(tuple(obj))\n",
    "validation_negatives = v_negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_set = validation_positives + validation_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-purchase baseline: just rank which items are popular\n",
    "\n",
    "items_purchased = defaultdict(int)\n",
    "total_purchases = 0\n",
    "\n",
    "for l in train_100k:\n",
    "    item = l['itemID']\n",
    "    items_purchased[item] += 1\n",
    "    total_purchases += 1\n",
    "\n",
    "mostPopular = [(items_purchased[x], x) for x in items_purchased]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > total_purchases/2: break\n",
    "\n",
    "predictions = []\n",
    "for u,i in v_set:\n",
    "    if i in return1:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_Purchase_list = []\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    obj = tuple([u,i])\n",
    "    pairs_Purchase_list.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated user_cat_tup_array [(userID, category),]\n"
     ]
    }
   ],
   "source": [
    "user_cat_tup_array = [] # [('UserID', 'category'), ]\n",
    "#pbar = tqdm_notebook(total=28000, desc='Progress:')\n",
    "\n",
    "for l in pairs_Purchase_list: # [(userID,itemID)]\n",
    "    u_id = l[0]\n",
    "    i_id = l[1]\n",
    "    #ui_tup = tuple([u_id,i_id])\n",
    "\n",
    "    for k in train_200k:\n",
    "        if i_id == k['itemID']:\n",
    "            c_id = k['categoryID']\n",
    "            break\n",
    "        else:\n",
    "            print('yo we dont know what this category is')\n",
    "            # TODO: sentiment analysis for category\n",
    "            c_id = 0 # if category is unknown, assume the most popular\n",
    "                    # which is women (0)\n",
    "                \n",
    "    user_cat_tup_array.append(tuple([u_id, c_id]))\n",
    "    #pbar.update(1)\n",
    "#pbar.close()\n",
    "print('Generated user_cat_tup_array [(userID, category),]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once\n",
    "'''\n",
    "tup_file = open(\"user_cat_tup_array.txt\", 'w')\n",
    "for l in user_cat_tup_array:\n",
    "    tup_file.write(str(l) + '\\n')\n",
    "tup_file.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categories': [['Sports & Outdoors',\n",
       "   'Clothing',\n",
       "   'Women',\n",
       "   'Shirts',\n",
       "   'T-Shirts'],\n",
       "  ['Clothing, Shoes & Jewelry', 'B', 'Bella'],\n",
       "  ['Clothing, Shoes & Jewelry',\n",
       "   'Women',\n",
       "   'Clothing',\n",
       "   'Tops & Tees',\n",
       "   'Knits & Tees'],\n",
       "  ['Clothing, Shoes & Jewelry',\n",
       "   'Novelty, Costumes & More',\n",
       "   'Band & Music Fan',\n",
       "   'T-Shirts']],\n",
       " 'categoryID': 0,\n",
       " 'helpful': {'nHelpful': 0, 'outOf': 0},\n",
       " 'itemID': 'I872967861',\n",
       " 'rating': 5.0,\n",
       " 'reviewHash': 'R502044342',\n",
       " 'reviewText': 'I love the way the shirt fits  but should have gotten a size smaller...i usually wear a medium so these must run bigger..but is okay...i will wear a cami underneath and will take care of that...droops to close to my shoulders....a small would have fit better....',\n",
       " 'reviewTime': '02 27, 2014',\n",
       " 'reviewerID': 'U533582985',\n",
       " 'summary': 'Flowy Draped Sleeve Dolman T-Shirt',\n",
       " 'unixReviewTime': 1393459200}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_100k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% complete\n",
      "1% complete\n",
      "2% complete\n",
      "3% complete\n",
      "4% complete\n",
      "5% complete\n",
      "6% complete\n",
      "7% complete\n",
      "8% complete\n",
      "9% complete\n",
      "10% complete\n",
      "11% complete\n",
      "12% complete\n",
      "13% complete\n",
      "14% complete\n",
      "15% complete\n",
      "16% complete\n",
      "17% complete\n",
      "18% complete\n",
      "19% complete\n",
      "20% complete\n",
      "21% complete\n",
      "22% complete\n",
      "23% complete\n",
      "24% complete\n",
      "25% complete\n",
      "26% complete\n",
      "27% complete\n",
      "28% complete\n",
      "29% complete\n",
      "30% complete\n",
      "31% complete\n",
      "32% complete\n",
      "33% complete\n",
      "34% complete\n",
      "35% complete\n",
      "36% complete\n",
      "37% complete\n",
      "38% complete\n",
      "39% complete\n",
      "40% complete\n",
      "41% complete\n",
      "42% complete\n",
      "43% complete\n",
      "44% complete\n",
      "45% complete\n",
      "46% complete\n",
      "47% complete\n",
      "48% complete\n",
      "49% complete\n",
      "50% complete\n",
      "51% complete\n",
      "52% complete\n",
      "53% complete\n",
      "54% complete\n",
      "55% complete\n",
      "56% complete\n",
      "57% complete\n",
      "58% complete\n",
      "59% complete\n",
      "60% complete\n",
      "61% complete\n",
      "62% complete\n",
      "63% complete\n",
      "64% complete\n",
      "65% complete\n",
      "66% complete\n",
      "67% complete\n",
      "68% complete\n",
      "69% complete\n",
      "70% complete\n",
      "71% complete\n",
      "72% complete\n",
      "73% complete\n",
      "74% complete\n",
      "75% complete\n",
      "76% complete\n",
      "77% complete\n",
      "78% complete\n",
      "79% complete\n",
      "80% complete\n",
      "81% complete\n",
      "82% complete\n",
      "83% complete\n",
      "84% complete\n",
      "85% complete\n",
      "86% complete\n",
      "87% complete\n",
      "88% complete\n",
      "89% complete\n",
      "90% complete\n",
      "91% complete\n",
      "92% complete\n",
      "93% complete\n",
      "94% complete\n",
      "95% complete\n",
      "96% complete\n",
      "97% complete\n",
      "98% complete\n",
      "99% complete\n"
     ]
    }
   ],
   "source": [
    "# here be the predictor\n",
    "usersNeverSeen = 0\n",
    "predictedViaCat = 0\n",
    "popularityMetric = 0\n",
    "counter = 0\n",
    "predictions = []\n",
    "\n",
    "for t in user_cat_tup_array: # 28k times \n",
    "    if (counter % 2800) == 0:\n",
    "        print(str(counter/280) + '% complete')\n",
    "    if t in user_categories: # if the person bought the same category of item before\n",
    "        predictions.append(1) # predict yes\n",
    "        predictedViaCat += 1\n",
    "        counter += 1\n",
    "        continue\n",
    "    if t[0] not in uniqueUsers:\n",
    "        # if t[0] is like another user who bought the item\n",
    "        #predictions.append(1) # predict yes\n",
    "        usersNeverSeen += 1\n",
    "    if :\n",
    "        predictions.append(1)\n",
    "        popularityMetric += 1\n",
    "        counter += 1\n",
    "        continue\n",
    "    predictions.append(0)\n",
    "    counter += 1 \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "zipped = list(zip(pairs_Purchase_list, predictions))\n",
    "file = open('purchase_prediction_results.txt', 'w')\n",
    "file.write('reviewerID-itemID,prediction\\n')\n",
    "for l in zipped:\n",
    "    file.write(str(l[0][0]) + '-' + str(l[0][1]) + ',' + str(l[1]) + '\\n')\n",
    "file.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "19695\n",
      "0\n",
      "[('U938994110', 'I529819131'), ('U181459539', 'I863471064'), ('U941668816', 'I684585522'), ('U768449391', 'I782253949'), ('U640450168', 'I232683472')]\n"
     ]
    }
   ],
   "source": [
    "print(usersNeverSeen)\n",
    "print(predictedViaCat)\n",
    "print(popularityMetric)\n",
    "print(pairs_Purchase_list[:5])\n",
    "#print(mostPopular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
