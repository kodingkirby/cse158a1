{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Lock, Process, Queue, current_process, Pool\n",
    "import random\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "import time\n",
    "import sys\n",
    "#import queue # imported for using queue.Empty exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks: Purchase Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Although we have built a validation set, it only consists of positive samples. For this task we also need examples of user/item pairs that weren’t purchased. Build such a set by randomly sampling users and items until you have 100,000 non-purchased user/item pairs. This random sample combined with your 100,000 validation reviews now corresponds to the complete validation set for the purchase prediction task. Evaluate the performance (accuracy) of the baseline model on the validation set you have built (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate list of possible choices to pick from for users\\\n",
    "allUsers = set([])\n",
    "allItems = set([])\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    allUsers.add(user)\n",
    "    allItems.add(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# optionally save it to disk (Also practicing parallelism \n",
    "# here, it will be useful later on)\n",
    "persist = True\n",
    "processes = []\n",
    "\n",
    "if persist:\n",
    "    def save_items():\n",
    "        itemsSet = open(\"items_set.txt\", 'w')\n",
    "        for l in allItems:\n",
    "            itemsSet.write(l + '\\n')\n",
    "        itemsSet.close()\n",
    "        \n",
    "    def save_users():\n",
    "        usersSet = open(\"users_set.txt\", 'w')\n",
    "        for l in allUsers:\n",
    "            usersSet.write(l + '\\n')\n",
    "        usersSet.close()\n",
    "        \n",
    "    def parallel_execute():\n",
    "        p = Process(target=save_items)\n",
    "        q = Process(target=save_users)\n",
    "        processes.append(p)\n",
    "        processes.append(q)\n",
    "        p.start()\n",
    "        q.start()\n",
    "        p.join() # comment this out to allow other cells to run\n",
    "        q.join() # ''\n",
    "        #p.close()\n",
    "        #q.close()\n",
    "    parallel_execute()\n",
    "    \n",
    "uniqueUsers = list(allUsers)\n",
    "uniqueItems = list(allItems)\n",
    "print('Done') # should let me run other cells while jobs finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IntProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd91e6411c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_200k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpurchases_200k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Progress:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreadGz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.json.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py37/lib/python2.7/site-packages/tqdm/__init__.pyc\u001b[0m in \u001b[0;36mtqdm_notebook\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"\"\"See tqdm._tqdm_notebook.tqdm_notebook for full documentation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_tqdm_notebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tqdm_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py37/lib/python2.7/site-packages/tqdm/_tqdm_notebook.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# Replace with IPython progress bar display (with correct total)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         self.sp = self.status_printer(\n\u001b[0;32m--> 212\u001b[0;31m             self.fp, self.total, self.desc, self.ncols)\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m  \u001b[0;31m# trick to place description before the bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py37/lib/python2.7/site-packages/tqdm/_tqdm_notebook.pyc\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# #187 #451 #558\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             raise ImportError(\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0;34m\"IntProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[0;31mImportError\u001b[0m: IntProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# load sets of data in memory\n",
    "train_200k = []\n",
    "purchases_200k = []\n",
    "pbar = tqdm_notebook(total=200000, desc='Progress:')\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    train_200k.append(l)\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    # appending as tuple to allow hash collision detection\n",
    "    # later on down the line\n",
    "    purchases_200k.append((user,item))\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_negatives = []\n",
    "purchases_to_generate = range(100000)\n",
    "\n",
    "pool = Pool(processes=3)\n",
    "#progress = tqdm_notebook(total=len(purchases_to_generate), desc='Progress:')\n",
    "\n",
    "def generate_fake_purchase(counter):\n",
    "    while True:\n",
    "        unique = True\n",
    "        #if (counter % 1000) == 0:\n",
    "        #    print(str(int(counter/1000)) + '% complete')\n",
    "        randreviewer = random.choice(uniqueUsers)\n",
    "        randitem = random.choice(uniqueItems)  \n",
    "        randtuple = tuple([randreviewer, randitem]) # hash friendly format\n",
    "\n",
    "        if randtuple in purchases_200k:\n",
    "            unique = False\n",
    "            #print('pair already exists in purchases_200k')\n",
    "        elif randtuple in validation_negatives:\n",
    "            unique = False\n",
    "            #print('pair already exists in validation_negs')\n",
    "        else:\n",
    "            #progress.update(1)\n",
    "            return randtuple\n",
    "\n",
    "\n",
    "validation_negatives = pool.imap(generate_fake_purchase, purchases_to_generate)\n",
    "pool.close() #no more work\n",
    "pool.join()\n",
    "#progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create the final validation set consisting of \n",
    "# 100k positive + 100k negative values & clean up vars\n",
    "train_100k = train_200k[:100000]\n",
    "validation_positives = purchases_200k[100000:]\n",
    "v_set = validation_positives + validation_negatives\n",
    "v_negs = open(\"validation_negatives.txt\", 'w')\n",
    "for l in validation_negatives:\n",
    "    v_negs.write(str(l) + '\\n')\n",
    "v_negs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load presaved data\n",
    "import re\n",
    "train_100k = train_200k[:100000]\n",
    "validation_positives = purchases_200k[100000:]\n",
    "\n",
    "v_negs = []\n",
    "for l in open(\"validation_negatives.txt\"):\n",
    "    obj = l.split('\\'')[1::2]\n",
    "    v_negs.append(tuple(obj))\n",
    "validation_negatives = v_negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_set = validation_positives + validation_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-purchase baseline: just rank which items are popular\n",
    "\n",
    "items_purchased = defaultdict(int)\n",
    "total_purchases = 0\n",
    "\n",
    "for l in train_100k:\n",
    "    item = l['itemID']\n",
    "    items_purchased[item] += 1\n",
    "    total_purchases += 1\n",
    "\n",
    "mostPopular = [(items_purchased[x], x) for x in items_purchased]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > total_purchases/2: break\n",
    "\n",
    "predictions = []\n",
    "for u,i in v_set:\n",
    "    if i in return1:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "# Everything < 100k should be 1 and everything above that should be a 0\n",
    "counter = 0\n",
    "for i in predictions[:100000]:\n",
    "    if i == 1:\n",
    "        counter +=1\n",
    "for i in predictions[100000:]:\n",
    "    if i == 0:\n",
    "        counter +=1\n",
    "accuracy = counter/200000\n",
    "print(\"Accuracy: \" + str(accuracy*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The existing ‘purchase prediction’ baseline just returns True if the item in question is ‘popular,’ using a threshold of the 50th percentile of popularity (totalPurchases/2). Assuming that the ‘non-purchased’ test examples are a random sample of user-purchase pairs, is this particular threshold value the best? If not, see if you can find a better one (and report its performance), or if so, explain why it is the best (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Would-purchase baseline: just rank which items are popular\n",
    "def run_baseline(denominator):\n",
    "    items_purchased = defaultdict(int)\n",
    "    total_purchases = 0\n",
    "\n",
    "    for l in train_100k:\n",
    "        item = l['itemID']\n",
    "        items_purchased[item] += 1\n",
    "        total_purchases += 1\n",
    "\n",
    "    mostPopular = [(items_purchased[x], x) for x in items_purchased]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > total_purchases/denominator: break\n",
    "\n",
    "    predictions = []\n",
    "    for u,i in v_set:\n",
    "        if i in return1:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    # Everything < 100k should be 1 and everything above that should be a 0\n",
    "    counter = 0\n",
    "    for i in predictions[:100000]:\n",
    "        if i == 1:\n",
    "            counter +=1\n",
    "    for i in predictions[100000:]:\n",
    "        if i == 0:\n",
    "            counter +=1\n",
    "    accuracy = counter/200000\n",
    "    return accuracy\n",
    "    #print(\"denominator = \" + str(denominator) + \" accuracy: \" + str(accuracy*100) + \"%\")\n",
    "\n",
    "baseline_accuracy = run_baseline(2) # original value, 50th percentile\n",
    "with Pool(processes=3) as pool: #start 3 worker processes\n",
    "    accuracies = pool.map(run_baseline, range(1,90))\n",
    "#print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "flag = False\n",
    "for i in accuracies:\n",
    "    if i > baseline_accuracy:\n",
    "        flag = True\n",
    "        print('denom: ' + str(count) + ' accuracy: ' + str(i*100) + '%')\n",
    "if flag == False:\n",
    "    print('None of the trials beat the baseline')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no threshhold value that outperforms the original 50th percentile metric. It appears to perform the best because it has the highest accuracy when considering that particular subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Users may tend to repeatedly purchase items of the same type. Build a baseline that returns ‘True’ if a user has purchased an item of the same category before (at least one category in common), or zero otherwise (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = set([])\n",
    "\n",
    "for l in train_100k:\n",
    "    user = l['reviewerID']\n",
    "    category = l['categoryID']\n",
    "    obj = tuple([user,category])\n",
    "    results.add(obj)\n",
    "    \n",
    "user_categories = list(results)    \n",
    "#print(user_categories[:3])\n",
    "\n",
    "validation_positives = []\n",
    "for l in train_200k[100000:]:\n",
    "    user = l['reviewerID']\n",
    "    category = l['categoryID']\n",
    "    obj = tuple([user,category])\n",
    "    validation_positives.append(obj)\n",
    "\n",
    "#print(validation_positives[:3])\n",
    "validation_negatives = []\n",
    "while len(validation_negatives) < 100000:\n",
    "    tup = random.choice(user_categories)\n",
    "    user = tup[0]\n",
    "    category = random.randrange(1,5)\n",
    "    obj = tuple([user,category])\n",
    "    #print('generated')\n",
    "    if obj not in validation_positives:\n",
    "        validation_negatives.append(obj)\n",
    "        #print('added')\n",
    "        #print(obj)\n",
    "#print(validation_negatives[:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "predictions_pos = []\n",
    "for l in validation_positives:\n",
    "    if l in user_categories:\n",
    "        predictions_pos.append(1)\n",
    "        counter +=1\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "predictions_neg = []\n",
    "for l in validation_negatives:\n",
    "    if l in user_categories:\n",
    "        predictions_neg.append(1)\n",
    "    else:\n",
    "        predictions_neg.append(0)\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of predictor: ' + str(counter/200000*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To run our model on the test set, we’ll have to use the files ‘pairs Purchase.txt’ to find the review- erID/itemID pairs about which we have to make predictions. Using that data, run the above model and upload your solution to Kaggle. Tell us your Kaggle user name (1 mark). If you’ve already uploaded a better solution to Kaggle, that’s fine too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Username: https://www.kaggle.com/kodingkirby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_Purchase_list = []\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        #header\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    obj = tuple([u,i])\n",
    "    pairs_Purchase_list.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cat_tup_array = [] # [('UserID', 'category'), ]\n",
    "pbar = tqdm_notebook(total=28000, desc='Progress:')\n",
    "\n",
    "for l in pairs_Purchase_list: # [(userID,itemID)]\n",
    "    u_id = l[0]\n",
    "    i_id = l[1]\n",
    "    #ui_tup = tuple([u_id,i_id])\n",
    "\n",
    "    for k in train_200k:\n",
    "        if i_id == k['itemID']:\n",
    "            c_id = k['categoryID']\n",
    "            break\n",
    "        else:\n",
    "            c_id = 0 # if category is unknown, assume the most popular\n",
    "                    # which is women (0)\n",
    "                \n",
    "    user_cat_tup_array.append(tuple([u_id, c_id]))\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "print('Generated user_cat_tup_array [(userID, category),]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "predictions = []\n",
    "pbar = tqdm_notebook(total=28000, desc='Progress:')\n",
    "\n",
    "for t in user_cat_tup_array: # 28k times\n",
    "    if t in user_categories:\n",
    "        predictions.append(1)\n",
    "        counter +=1\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = list(zip(pairs_Purchase_list, predictions))\n",
    "file = open('q4_results.txt', 'w')\n",
    "file.write('reviewerID-itemID,prediction\\n')\n",
    "for l in zipped:\n",
    "    file.write(str(l[0][0]) + '-' + str(l[0][1]) + ',' + str(l[1]) + '\\n')\n",
    "file.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
